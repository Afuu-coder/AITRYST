import { NextResponse } from 'next/server';
import { transcribeAudioWithVertex, generateProductContentFromTranscription } from '@/lib/vertexAIServer';
import { Buffer } from 'buffer';
import { NextRequest } from 'next/server';

export async function POST(request: NextRequest) {
  try {
    console.log('üé§ Transcription API called');
    
    // Get the audio file and language from the request
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File | null;
    const language = formData.get('language') as string | null;
    
    if (!audioFile) {
      console.log('‚ùå No audio file provided');
      return NextResponse.json(
        { error: 'No audio file provided' },
        { status: 400 }
      );
    }
    
    console.log('üìÅ Audio file received:', {
      name: audioFile.name,
      size: audioFile.size,
      type: audioFile.type,
      language: language || 'en-US'
    });
    
    // Convert the file to a Buffer
    const arrayBuffer = await audioFile.arrayBuffer();
    const audioBuffer = Buffer.from(arrayBuffer);
    
    // Get the MIME type
    const mimeType = audioFile.type || 'audio/wav';
    console.log('üéß Incoming audio details:', { mimeType, size: audioFile.size });
    
    // Transcribe the audio using Google Cloud Speech-to-Text
    console.log('üîÑ Starting transcription...');
    let transcription: string = '';
    try {
      transcription = await transcribeAudioWithVertex(audioBuffer, mimeType, language || undefined);
      console.log('‚úÖ Transcription completed:', transcription.substring(0, 100) + '...');
    } catch (sttError) {
      console.warn('‚ö†Ô∏è STT failed, using fallback transcription:', sttError);
      // Minimal fallback to allow flow to continue
      const lang = (language || 'en-US').toLowerCase();
      if (lang.startsWith('hi')) {
        transcription = '‡§Ø‡§π ‡§è‡§ï ‡§°‡•á‡§Æ‡•ã ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§∏‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§ï‡§∞‡•á‡§Ç‡•§';
      } else if (lang.startsWith('bn')) {
        transcription = '‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶°‡ßá‡¶Æ‡ßã ‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶∏‡¶ï‡ßç‡¶∞‡¶ø‡¶™‡¶∂‡¶®‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶∏‡¶≤ ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶∞‡ßá‡¶ï‡¶∞‡ßç‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®‡•§';
      } else if (lang.startsWith('te')) {
        transcription = '‡∞á‡∞¶‡∞ø ‡∞°‡±Ü‡∞Æ‡±ã ‡∞ü‡±ç‡∞∞‡∞æ‡∞®‡±ç‡∞∏‡±ç‡∞ï‡±ç‡∞∞‡∞ø‡∞™‡±ç‡∞∑‡∞®‡±ç. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Ö‡∞∏‡∞≤‡±Å ‡∞Ü‡∞°‡∞ø‡∞Ø‡±ã‡∞®‡±Å ‡∞∞‡∞ø‡∞ï‡∞æ‡∞∞‡±ç‡∞°‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.';
      } else {
        transcription = 'This is a demo transcription. Please record real audio.';
      }
    }
    
    // Generate product content from transcription
    console.log('üîÑ Generating product content...');
    
    // Map the language code to the correct language for content generation
    let contentLanguage: 'en' | 'hi' | 'bn' | 'te' = 'en';
    if (language) {
      if (language.includes('hi')) {
        contentLanguage = 'hi';
      } else if (language.includes('bn')) {
        contentLanguage = 'bn';
      } else if (language.includes('te')) {
        contentLanguage = 'te';
      } else {
        contentLanguage = 'en';
      }
    }
    
    console.log('üåê Content generation language:', contentLanguage, 'for transcription language:', language);
    let productContent: any;
    try {
      productContent = await generateProductContentFromTranscription(transcription, contentLanguage);
      console.log('‚úÖ Product content generated successfully');
    } catch (genError) {
      console.warn('‚ö†Ô∏è Product content generation failed, using fallback:', genError);
      // Simple fallback content
      productContent = {
        title: contentLanguage === 'hi' ? '‡§π‡§∏‡•ç‡§§‡§®‡§ø‡§∞‡•ç‡§Æ‡§ø‡§§ ‡§â‡§§‡•ç‡§™‡§æ‡§¶' : contentLanguage === 'bn' ? '‡¶π‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶°‡¶ï‡ßç‡¶∞‡¶æ‡¶´‡¶ü‡ßá‡¶° ‡¶™‡¶£‡ßç‡¶Ø' : contentLanguage === 'te' ? '‡∞π‡±ç‡∞Ø‡∞æ‡∞Ç‡∞°‡±ç‚Äå‡∞ï‡±ç‡∞∞‡∞æ‡∞´‡±ç‡∞ü‡±ç ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø' : 'Handcrafted Product',
        description: `${transcription}\n\n` + (contentLanguage === 'hi'
          ? '‡§Ø‡§π ‡§è‡§ï ‡§∏‡•ç‡§µ‡§ö‡§æ‡§≤‡§ø‡§§ ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡§®‡§æ‡§à ‡§ó‡§à ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§π‡•à‡•§'
          : contentLanguage === 'bn'
          ? '‡¶è‡¶ü‡¶ø ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶≠‡¶æ‡¶¨‡ßá ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶ï‡¶®‡ßç‡¶ü‡ßá‡¶®‡ßç‡¶ü‡•§'
          : contentLanguage === 'te'
          ? '‡∞á‡∞¶‡∞ø ‡∞∏‡±ç‡∞µ‡∞Ø‡∞Ç‡∞ö‡∞æ‡∞≤‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞ø‡∞® ‡∞ï‡∞Ç‡∞ü‡±Ü‡∞Ç‡∞ü‡±ç.'
          : 'This is auto-generated content.')
      };
    }
    
    return NextResponse.json({ 
      transcription,
      productContent,
      language: language || 'en-US',
      success: true 
    });
  } catch (error) {
    console.error('‚ùå Error transcribing audio:', error);
    return NextResponse.json(
      { 
        error: 'Failed to transcribe audio',
        message: error instanceof Error ? error.message : 'Unknown error',
        success: false
      },
      { status: 500 }
    );
  }
}